# 基于Keras VGG19的图像风格迁移
本项目旨在将基础图像的风格转换为风格参考图像的相似风格，然后输出。

##项目的应用场景：

图像风格迁移技术旨在将一幅图像(风格图像)的艺术风格应用到另一幅图像(内容图像)上，同时保留内容图像的主要内容。该技术在艺术创作、广告设计、游戏开发等多个领域具有广泛的应用价值。通过深度学习算法，图像风格迁移技术能够自动地识别和提取图像中的风格和内容特征，实现高效的风格转换。
图像风格迁移技术主要基于深度学习算法，尤其是卷积神经网络(CNN)。这些网络能够提取图像中的多层级特征,从而实现对图像内容和风格的分离与重组。在风格迁移过程中，通常使用预训练的CNN模型(如VGGNet、Inception等)来提取图像的特征。


##项目原理:

首先基础内容图像、风格参考图像和生成图像之间有两层关系，一层是生成图和内容图像的内容相似性，另一层是生成图和风格参考图的风格相似性;所以可以定义两个损失函数，即内容损失函数和风格损失函数，一个衡量了生成图和内容图的内容差异，另一个衡量了生成图和风格图的风格差异，可以计算损失函数具体数值，损失函数越小，所代表的差异越小;最后参数a乘以内容损失函数加上参数b乘以风格损失函数得到总的损失函数，总损失函数即表现了图像风格迁移的效果的好坏。


##项目实现：

首先随机初始化一个白噪声的图像，如一个长为300像素，宽为200 像素,3通道的彩色图像,将该白噪声图像输入到深度卷积神经网络VGG19中,由VGG19各层产生的中间层的特征来计算内容和风格损失函数，从而得到总的损失函数;接下来计算总的损失函数相对于每一个像素的梯度,这样相当于就知道了各个像素变大或变小会对总损失函数产生什么样的影响(增大或减小)，于是根据学习率微调每个像素的值，再次将该图像输入到 VGG19 中计算总损失函数，迭代这个过程n次，使得这个损失函数逐渐降低，当迭代次数或损失函数达到想要的值时，停止迭代，得到风格迁移的最终图像。
